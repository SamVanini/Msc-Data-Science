{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a7798f",
   "metadata": {},
   "source": [
    "# Data analysis from zero to hero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b1cb4",
   "metadata": {},
   "source": [
    "## Imports section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7e3fe",
   "metadata": {},
   "source": [
    "## First step: load your data set\n",
    "\n",
    "For analyze a bunch of data you have, of course, to load it in the right way.\n",
    "\n",
    "Depending on the type of data you are gonna analyze, there are various ways to import the related DataFrame.\n",
    "For instance:\n",
    "- CSV: pd.read_csv(\"file/path/to/data.csv\", sep=\";\")\n",
    "- Excel: pd.read_excel(\"file/path/to/data.xlsx\")\n",
    "- JSON: pd.read_json(\"file/path/to/data.json\")\n",
    "- HTML: pd.read_html(\"file/path/to/data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3064d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"sample_data\", \"housing.csv\")\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402f951",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "First of all, you have to look arond your data, in order to understand the basic features of the data frame\n",
    "\n",
    "Adviced steps are the following one:\n",
    "- Visualize the first 5 and the last 5 rows using df.head() and df.tail() respectively\n",
    "- Have a look at the shape of the data set, using df.shape\n",
    "- Visualize the available columns using df.columns\n",
    "- Check data types using df.dtypes\n",
    "\n",
    "For a brief look at the statistics and null values:\n",
    "- df.describe() and df.describe().T\n",
    "- df.info()\n",
    "- df.isna().sum().sum() for overall count, only one sum for count by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca07578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75388ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b33c05",
   "metadata": {},
   "source": [
    "## Manage null values\n",
    "\n",
    "It can happen to have null values in columns\n",
    "\n",
    "Depending on their importance in your analysis you can either drop them or fill them with a suitable value (e.g the column mean)\n",
    "\n",
    "Note: this type of operation should be done on a copy of the original dataset, better safe than sorry\n",
    "\n",
    "Note 2: the use of inPlace=True on some operations has been marked with a FutureWarning, so it is better to avoid it in favour of assignment. Other reasons to do it are clarity, readibility, and intention driven behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119461dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['column_with_null_values'] = df['column_with_null_values'].dropna()\n",
    "# df['column_with_null_values'] = df['column_with_null_values'].fillna(df['column_with_null_values'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c3e62",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "You may want to visualize or treat only a slice of the original Pandas series (column).\n",
    "It can be done using boolean masks, their syntax is quite simple, but they are very useful sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean_mask = series_name > value\n",
    "# boolean_mask_and = (series_name > value) & (series_name < value)\n",
    "# boolean_mask_or = (series_name < value) || (series_name == value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601cc5e",
   "metadata": {},
   "source": [
    "Another useful feature could be column renaming, in order to clarify what does that series contain. Or, more trivial, you may want to capitalize or format the name somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.map(lamda col: col.capitalize())\n",
    "# df.columns = df.columns.map(str.capitalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d62cb",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Visualize the data you are working with in order to extract hidden features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(10, 10), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb4fde",
   "metadata": {},
   "source": [
    "### Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10840928",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(0, 21))\n",
    "y = [i**2 for i in x]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, y)\n",
    "plt.title('Square of X')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c888a",
   "metadata": {},
   "source": [
    "### Scatter\n",
    "\n",
    "c indicates the color to give at the scatter chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, c=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d3c1f",
   "metadata": {},
   "source": [
    "### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['MS', 'Apple', 'Meta', 'Google', 'Amazon']\n",
    "stock_prices = [130, 112, 145, 180, 201]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "bars = plt.bar(labels, stock_prices)\n",
    "bars[2].set_hatch('.')\n",
    "bars[0].set_width(0.2)\n",
    "bars[1].set_color('red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122ef3e",
   "metadata": {},
   "source": [
    "### Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32829c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sb.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc25157",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "This step is needed to remove outliers in order to have a smoother data set\n",
    "\n",
    "The procedure here usually consists in replacing the outliers with the mean value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446951d0",
   "metadata": {},
   "source": [
    "## Aggregations and grouping\n",
    "\n",
    "Like an SQL statement, it may be necessary to group data by a column in order to analyze data by categories or groups, such as calculating summary statistics like the mean, sum, or count for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_df = df.groupby('COL_NAME').agg({'COL_1': fun1, 'COL_2': fun2})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
